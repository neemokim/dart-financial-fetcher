import fitz  # PyMuPDF
import re
import requests
import os
from bs4 import BeautifulSoup
import requests


# PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_pdf_url(pdf_url):
    response = requests.get(pdf_url)
    if response.status_code != 200:
        raise Exception("PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

    # PDF ì‘ë‹µì´ ë§ëŠ”ì§€ ì²´í¬ (ì‘ë‹µ í—¤ë” ë˜ëŠ” ë‚´ìš© ì•ë¶€ë¶„)
    if not response.headers["Content-Type"].startswith("application/pdf"):
        print("âŒ PDF ì•„ë‹˜! ì‘ë‹µ í—¤ë”:", response.headers)
        print("ğŸ“¦ ì‘ë‹µ ë‚´ìš©:", response.text[:200])
        raise Exception("PDFê°€ ì•„ë‹Œ ì‘ë‹µì´ ë°˜í™˜ë¨")

    temp_filename = "temp.pdf"
    with open(temp_filename, "wb") as f:
        f.write(response.content)

    text = ""
    with fitz.open(temp_filename) as doc:
        for page in doc:
            text += page.get_text()

    os.remove(temp_filename)
    return text

    temp_filename = "temp.pdf"
    with open(temp_filename, "wb") as f:
        f.write(response.content)

    text = ""
    with fitz.open(temp_filename) as doc:
        for page in doc:
            text += page.get_text()

    os.remove(temp_filename)
    return text

# í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©)
def extract_financials_from_text(text):
    # ìˆ«ì ì¶”ì¶œ ì •ê·œí‘œí˜„ì‹ (ë‹¨ìœ„: ì–µ ì›, ì¡° ì› ë“± í¬í•¨ ê°€ëŠ¥)
    def find_value(keyword):
        pattern = rf"{keyword}[\s:ï¼š\-]*([\d,]+)"
        match = re.search(pattern, text.replace(",", ""), re.IGNORECASE)
        return match.group(1) if match else "ì—†ìŒ"

    return {
        "ìë³¸ì´ê³„": find_value("ìë³¸ì´ê³„"),
        "ë¶€ì±„ì´ê³„": find_value("ë¶€ì±„ì´ê³„"),
        "ë§¤ì¶œì•¡": find_value("ë§¤ì¶œì•¡"),
        "ì˜ì—…ì´ìµ": find_value("ì˜ì—…ì´ìµ")
    }

# í†µí•© í•¨ìˆ˜ (PDF URLë§Œ ì…ë ¥ë°›ì•„ ê²°ê³¼ ë°˜í™˜)
def parse_external_audit_pdf(pdf_url):
    try:
        text = extract_text_from_pdf_url(pdf_url)
        return extract_financials_from_text(text)
    except Exception as e:
        return {"ì˜¤ë¥˜": str(e)}

# rcp_no â†’ ì§„ì§œ PDF ë‹¤ìš´ë¡œë“œ URL ìë™ ì¶”ì¶œ í•¨ìˆ˜
def get_pdf_download_url(rcp_no):
    """
    rcp_noë¥¼ ì´ìš©í•´ DART ë³´ê³ ì„œ í˜ì´ì§€ë¥¼ ì—´ê³ , PDF ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ì¶”ì¶œí•œë‹¤.
    """
    base_url = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcp_no}"
    response = requests.get(base_url)
    
    if response.status_code != 200:
        raise Exception("DART ë³´ê³ ì„œ ë³¸ë¬¸ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨")

    soup = BeautifulSoup(response.text, "html.parser")
    
    # PDF ë§í¬ ì°¾ê¸° (ì²¨ë¶€íŒŒì¼ ì„¹ì…˜ì—ì„œ)
    iframe = soup.find("iframe", {"id": "pdf"})
    if iframe and "src" in iframe.attrs:
        # ìƒëŒ€ ê²½ë¡œì¼ ê²½ìš° ì ˆëŒ€ ê²½ë¡œë¡œ ë°”ê¿”ì£¼ê¸°
        pdf_url = "https://dart.fss.or.kr" + iframe["src"]
        return pdf_url
    else:
        raise Exception("PDF ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ğŸ“„ "ê°€ì¥ ìµœì‹  ì™¸ë¶€ê°ì‚¬ë³´ê³ ì„œì˜ rcp_noë¥¼ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜" ë§Œë“¤ì–´ì¤„ê²Œ.
def get_latest_audit_rcp_no(corp_code, api_key):
    """
    ê¸°ì—…ì½”ë“œ ê¸°ì¤€ìœ¼ë¡œ ìµœê·¼ ê³µì‹œ ëª©ë¡ ì¤‘ 'ê°ì‚¬' í¬í•¨ëœ ë³´ê³ ì„œì˜ rcp_no ë°˜í™˜
    ì—°ë„ ì¡°ê±´ ì—†ì´ ì „ì²´ ë¦¬ìŠ¤íŠ¸ ì¤‘ì—ì„œ íƒìƒ‰í•¨
    """
    url = (
        f"https://opendart.fss.or.kr/api/list.json?"
        f"crtfc_key={api_key}&corp_code={corp_code}&page_count=100"
    )
    response = requests.get(url).json()

    if response.get("status") != "000":
        raise Exception(f"ê³µì‹œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {response.get('message')}")

    reports = response.get("list", [])

    for report in reports:
        if "ê°ì‚¬" in report.get("report_nm", ""):
            return report["rcp_no"]

    raise Exception("ê°ì‚¬ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ì´ë¦„ ì •ê·œí™”ë„ í¬í•¨ ì—°ë„ ì¡°ê±´ ì—†ì´ ê°ì‚¬ë³´ê³ ì„œ ìë™ íƒì§€
def normalize_name(name):
    return re.sub(r"[\sãˆœ(ì£¼)ì£¼ì‹íšŒì‚¬]", "", name.lower())

def get_corp_code(corp_name, corp_list_df):
    """
    (ì£¼), ê³µë°± ë“±ì„ ì œê±°í•œ ì •ê·œí™”ëœ ì´ë¦„ ê¸°ì¤€ìœ¼ë¡œ ê¸°ì—…ì½”ë“œ ì¡°íšŒ
    """
    norm_name = normalize_name(corp_name)
    corp_list_df["norm_name"] = corp_list_df["corp_name"].apply(normalize_name)
    match = corp_list_df[corp_list_df["norm_name"] == norm_name]
    if not match.empty:
        return match.iloc[0]["corp_code"]
    return None

