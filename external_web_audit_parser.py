import requests
from bs4 import BeautifulSoup
import re

def get_latest_web_rcp_no(corp_name):
    """
    ê¸°ì—…ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ DART ì›¹ì—ì„œ ì™¸ë¶€ê°ì‚¬ë³´ê³ ì„œì˜ rcpNoë¥¼ í¬ë¡¤ë§í•œë‹¤.
    """
    search_url = f"https://dart.fss.or.kr/dsap001/search.ax?textCrpNm={corp_name}"
    print(f"ğŸŒ ê²€ìƒ‰ URL: {search_url}")
    resp = requests.get(search_url)
    soup = BeautifulSoup(resp.text, "html.parser")

    # 'ë³´ê³ ì„œëª…'ì— 'ì™¸ë¶€ê°ì‚¬' í¬í•¨ëœ ê²ƒ ì¤‘ ê°€ì¥ ìµœê·¼ rcpNo ì°¾ê¸°
    links = soup.select("a[href*='rcpNo']")
    for link in links:
        title = link.get_text()
        if "ì™¸ë¶€ê°ì‚¬" in title:
            href = link["href"]
            match = re.search(r"rcpNo=(\d+)", href)
            if match:
                return match.group(1)

    raise Exception("ì›¹ì—ì„œ ì™¸ë¶€ê°ì‚¬ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def get_pdf_download_url(rcp_no):
    viewer_url = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcp_no}"
    resp = requests.get(viewer_url)
    soup = BeautifulSoup(resp.text, "html.parser")
    iframe = soup.find("iframe", {"id": "pdf"})
    if iframe and "src" in iframe.attrs:
        return "https://dart.fss.or.kr" + iframe["src"]
    raise Exception("PDF ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def parse_external_audit_pdf(pdf_url):
    import fitz  # PyMuPDF
    resp = requests.get(pdf_url)
    with open("temp.pdf", "wb") as f:
        f.write(resp.content)

    doc = fitz.open("temp.pdf")
    text = ""
    for page in doc:
        text += page.get_text()

    # ìˆ«ì ì¶”ì¶œ ì˜ˆì‹œ
    result = {}
    keywords = ["ìë³¸ì´ê³„", "ë¶€ì±„ì´ê³„", "ë§¤ì¶œì•¡", "ì˜ì—…ì´ìµ"]
    for key in keywords:
        match = re.search(f"{key}.{{0,20}}?([\d,]+)", text)
        result[key] = match.group(1) if match else "ì—†ìŒ"

    return result
